<!DOCTYPE html>
<html lang="en">

<head>

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="">
  <meta name="author" content="">

  <title>Stanford Earth Research Computing</title>

  <link rel="icon" href="img/logo_earth_map.jpg" type="image/x-icon">

  <!-- Bootstrap Core CSS -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" 
      integrity="sha256-916EbMg70RQy9LHiGkXzG8hSg9EdNy97GazNG/aiY1w=" crossorigin="anonymous" />

  <!-- Custom Fonts -->
  <link
  href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet"/>
  <link href='https://fonts.googleapis.com/css?family=Bangers' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  <link href='https://fonts.googleapis.com/css?family=Roboto:400,100,300,700' rel='stylesheet' type='text/css'>

  <!-- Theme CSS -->
  <link href="css/shweb.min.css" rel="stylesheet">

  <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
  <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
  <!--[if lt IE 9]>
    <script src="//oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
    <script src="//oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
  <![endif]-->

  <link href="https://www.stanford.edu/su-identity/css/su-identity.css" rel="stylesheet">
  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,700' rel='stylesheet' type='text/css'>
  <!--[if lt IE 9]>
    <script src="//html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <!--[if IE 8]>
    <link rel="stylesheet" type="text/css" href="https://www.stanford.edu/su-identity/css/ie/ie8.css" />
  <![endif]-->
  <!--[if IE 7]>
    <link rel="stylesheet" type="text/css" href="https://www.stanford.edu/su-identity/css/ie/ie7.css" />
  <![endif]-->

  <!-- noticeable.io widget (changelog) -->
  <script async="" defer="" src="https://cdn.noticeable.io/v1/noticeable-widget.js"></script>

  <!-- UserVoice widget -->
  <script async>
    // Include the UserVoice JavaScript SDK (only needed once on a page)
    UserVoice = window.UserVoice||[];(
      function() {
        var uv=document.createElement('script');
        uv.type='text/javascript';
        uv.async=true;
        uv.src='//widget.uservoice.com/4a4IvDVZKokz6bHpdbN6Q.js';
        var s=document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(uv,s)
      }
    )();
    UserVoice.push(['set', {
      accent_color: '#8C1515',
      ticket_custom_fields: {
        'System': 'CEES'
      },
      strings: {
        contact_message_placeholder: 'How could we help you?'
      }
    }]);
    var mesg_tmpl = 'Please indicate your name, SUNet ID, and PI, and we\'ll get back to you. Your PI\'s approval will be required.'
    for (i=1; i<=3; i++) {
        UserVoice.push(['addTrigger', '#account_request'+i, {
          position: 'top',
          width: '300px',
          height: '350px',
          screenshot_enabled: false,
          ticket_custom_fields: {
            'System': 'CEES'
          },
          strings: {
            contact_title: 'Sherlock account request',
            contact_message_placeholder: mesg_tmpl
          }
        }]);
    }
  </script>

  <!-- Google Analytics -->
  <!-- Having shamelessly borrowed this content as a template, these are not our GA credentials-->
  <!--
  //<script>
  //  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  //  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  //  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  //  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  //  ga('create', 'UA-68034405-2', 'auto');
  //  ga('send', 'pageview');
  </script>
  -->

</head>

<body id="page-top" class="index">

 <div id="su-wrap"> <!-- #su-wrap start -->
   <div id="su-content"> <!-- #su-content start -->

  <!-- Navigation -->
  <nav id="mainNav" class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container" >
      <!-- Brand and toggle get grouped for better mobile display -->
      <div class="navbar-header page-scroll
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
          <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
        </button>
        <a class="navbar-brand page-scroll" href="#page-top">
              <img src="img/stanford-earth-logo_transp.png" height="30" alt="">SERC
        </a>
      </div>

      <!-- Collect the nav links, forms, and other content for toggling -->
      <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1" >
      <div class="nav navbar-nav navbar-right"></div>
        <ul class="nav navbar-nav navbar-right">
          <li class="hidden">
            <a href="#page-top"></a>
          </li>
          <li>
            <span class="navbar-separator"></span>
          </li>
          <li>
            <a class="page-scroll" href="#sherlock">Sherlock</a>
          </li>
          <li>
          <a class="page-scroll" href="#mazama">Mazama</a>
          </li>
		  <li>
		  <a class="page-scroll" href="#rcf">RCF</a>
		  </li>
          <li>
            <a class="page-scroll" href="#info">Info</a>
          </li>
          <li>
            <a class="page-scroll" href="#about">About</a>
          </li>
          <li>
            <span class="navbar-separator"></span>
          </li>
          <li>
            <a class="page-scroll"
            href="https://status.sherlock.stanford.edu">Status: Sherlock (SERC)</a>
            <span id="status"/>
          </li>
          <li>
            <a class="page-scroll" href="https://news.sherlock.stanford.edu">News (SERC?)</a>
            <!--
            <noticeable-widget id="news"
            access-token="AoaqgE2gEgx8fjXbxETY" project-id="bYyIewUV308AvkMztxix">
            </noticeable-widget>
            -->
          </li>
          <li>
            <a class="page-scroll" href="/docs">Docs</a>
          </li>
          <li>
            <span class="navbar-separator"></span>
          </li>
          <li>
            <a class="page-scroll" href="" data-uv-trigger>Support</a>
          </li>
          <li>
            <a class="page-scroll" href="//srcc.stanford.edu">SRCC</a>
          </li>
          <li>
            <span class="navbar-separator"></span>
          </li>
        </ul>
      </div>
      <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
  </nav>

  <!-- Header -->
  <header>
    <div class="container">
      <div class="intro-text">
        <img height="180" src="img/hive_crew.jpg" alt="">
        <div class="intro-heading"><h3>Stanford Earth Research Computing</div>
        <div class="intro-subtitle">Stanford Earth profides a variety of high performance computing (HPC) resources to satisfy your research requirements.
        </div>
        <div class="intro-content">
        Resources available to EARTH researchers include:
        <ul>
        <li> SRCC <i>Sherlock</i> HPC cluster </li>
        <li> <i>Sherlock-SERC</i> HPC partition</li>
        <li> Mazama HPC cluster</li>
        <li> Mazama "Tool-Server" compute nodes </li>
        </ul>
        
        These systems provide a variety of tools and resources, including cluster-computing, interactive compute nodes, GPU computation, memory-intensive nodes, data storage, and more.
        
        Need to additional computing resources to
        support your Stanford Earth research?  You may
        want to try the SERC partition on the SRCC Sherlock cluster! Purchased and
        supported with seed
        funding from the Provost, Sherlock is a shared computing cluster
        available for use by all Stanford faculty and their research
        teams. The SERC partition is a collection of nodes dedicated for use by authorized
        teams from Stanford Earth.</div>

        <a href="#services" class="page-scroll btn btn-xl">Really? Tell me more</a>
        <a id="www_sherlock" href="https://sherlock.stanford.edu" class="page-scroll btn btn-xl">Request an account</a>
      </div>
    </div>
  </header>

<!-- Computing Resources Section -->
<section id="computing_resrouces">
    <div class="container">
        <div class="row">
            <div class="col-lg-12 text-center">
                <h2 class="section-heading">SERC Computing Resrouces</h2>
            </div>
        </div>
    </div>
 </section>

  <!-- Sherlock Section -->
  <section id="sherlock">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading"><i>Sherlock</i></h2>
          <h3 class="section-subheading text-muted"><i>A collaboration between Stanford Earth and Stanford Research Computing Center (SRCC) </i></h3>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12">
        <h4 id="sherlock_overview" class="airy">Overview:</h4>
            <p class="text-muted">
            The <i>Sherlock</i> HPC system, purchased and supported with seed funding from the Provost, is available for use by all Stanford faculty and their reserach teams. Sherlock is maintained by <a href="//srcc.stanford.edu">Stanford Research Computing Center</a> (SRCC); more information can be found at <a id="www_sherlock" href="https://www.sherlock.stanford.edu">https://www.sherlock.stanford.edu</a>. Sherlock's collaborative, shared resource approach facilitates scales of computing, varieties of available software, and levels of support that are not easily achieved by individual research groups or schools. </p>

        <h5 id="sherlock_serc" class="airy">Sherlock SERC Partition:</h5>
            <p class="text-muted">
                In addition to genearl access to Sherlock compute nodes, Stanford Earth maintains a dedicated <i>SERC partition</i> on Sherlock -- a set of nodes prioritized for use by SE3 researchers. The Fall, 2019 expansion of the SERC partition included 24 nodes with 192/384 GB RAM, and several GPU capable nodes. Contact somebody for more information on how to access the SERC partition.
            </p>
        <h5 id="sherlock_resources" class="airy">Sherlock Resources:</h5>
            <p class="text-muted">
                The Sherlock cluster includes a broad, capable variety of computing tools. It is difficult to say exactly how big, and what specific resources are available, because it is constantly in flux as users subscribe to the system, nodes are added, and old nodes are swapped out for new ones. Generally speaking, Sherlock provices:
                <ul class="text-muted">
                    <li>Traditional HPC "batch" computing, managed by SLURM</li>
                    <li>Interactive sessions, including multi-core instances</li>
                    <li>GPU nodes</li>
                    <li>Large memory nodes</li>
                </ul>
            </p>
			<h5 id="sherlock_ssh" class="airy">ssh (requires 2-factor auth):<br>
				$ ssh sherlock.stanford.edu</h5>
        <h5 id="sherlock_home" class="airy">Sherlock homepage: <a href=https://www.sherlock.stanford.edu>https://www.sherlock.stanford.edu</a></h5>
        <h5 id="sherlock_support_docs" class="airy">Sherlock support docs: <a href=https://www.sherlock.stanford.edu/docs/overview/introduction/>https://www.sherlock.stanford.edu/docs/overview/introduction/</a></h5>
            
            
        
        </div>
    </dif>
        
    </div>
  </section>
  
<!-- Mazama Section -->
  <section id="mazama">
      <div class="container">
          <div class="row">
              <div class="col-lg-12 text-center">
                  <h2 class="section-heading"><i>Mazama</i></h2>
                  <h3 class="section-subheading text-muted"><i>CEES HPC and Tool Servers</i></h3>
              </div>
          </div>
          <div class="row">
              <div class="col-lg-12">
                  <h4 id="mazama_overview" class="airy">Overview:</h4>
                  <p class="text-muted">
                    <i>Mazama</i> is a suite of compute resources, owned and opearated by Stanford Earth, that include:</p>
                    <ul class="text-muted">
                        <li> The Mazama HPC cluster (~150 nodes)</li>
                        <li> Interactive <i>Tool Server</i> nodes </li>
                        <li> Interactive GPU nodes </li>
                    </ul>
                    <h4 id="mazama_hpc" class="airy">Mazama HPC Cluster:</h4>
                        <ul class="text-muted">
                            <li> ~150 CentOS (RedHat Linux clone) Nodes</li>
                            <li><i>TORQUE/Maui</i> job scheduler</li>
                            <li>Interactive GPU nodes </li>
							<li><b>ssh (must be connected to VPN):<br>
								$ ssh {SUID}@cees-mazama.stanford.edu<b></li>
                            <li> <i>note: {SUID}@ is not requried if your SUID is the same as your workstation ID; .stanford.edu may not be necessary, since you're using the VPN</i>
                        </ul>
                    <h4 id='mazama_tool' class='airy'>Mazama Tool Servers</h4>
                        <ul class="text-muted">
                            <li>10 (?) Independent compute nodes/servers (not connected to cluster)</li>
                            <li>24 cores, 512GB RAM, but shared by multiple users simultaneously</li>
                            <li>Interactive workflow (jobs are not schedules; resources are not dedicated)</li>
                            <li>Can run Jupyter Notebooks (with a bit of work and trickery)</li>
                            <li><b>ssh (must be connected to VPN): {SUID}@cees-tool-{1-10}.stanford.edu<b></li>
                        </ul>
                        <h4 id='mazama_gpu' class='airy'>Mazama GPU Servers</h4>
                            <ul class="text-muted">
                                <li>GPU servers are tool servers with GPU cards</li>
                                <li>3 Independent compute nodes/servers (not connected to cluster)</li>
								<li><b>ssh (must be connected to VPN):<br>
									$ ssh {SUID}@cees{-gpu, -gpu-2, -gpu3}.stanford.edu<b></li>
                            </ul>
                    <h5 id=www_cees class='airy'>CEES website: <a href="https://cees.stanford.edu" target='_blank'> https://cees.stanford.edu</a> </h5>
                    <h5 id=mazama_pangea_docs class='airy'>CEES HPC general information: <a href="https://pangea.stanford.edu/research/groups/cees/hpc.php" target='_blank'> https://pangea.stanford.edu/research/groups/cees/hpc.php</a> </h5>
                  </p>
                  
              </div>
              </dif>
              
          </div>
          </section>
  <!-- RCF Section -->
  <section id="rcf">
	  <div class="container">
		  <div class="row">
			  <div class="col-lg-12 text-center">
				  <h2 class="section-heading"><i>RCF</i></h2>
				  <h3 class="section-subheading text-muted"></h3><i>RCF HPC Cluster</i>
			  </div>
		  </div>
		  <div class="row">
			  <div class="col-lg-12">
				  <h4 id="mazama_overview" class="airy">Overview:</h4>
				  <p class="text-muted">
				  <i>RCF</i> is a older, but quite capable, HPC cluster (~150 nodes?) owned  of compute resources, owned and opearated by Stanford Earth. General specifications include:</p>
				  <ul class="text-muted">
					  <li> ~150 CentOS (RedHat Linux clone) Nodes</li>
					  <li>  Dual Quad-core Nehalem (5520) cpus, 24 GB memory</li>
					  <li><i>TORQUE/Maui</i> job scheduler</li>
					  <li><b>ssh (must be connected to VPN):<br>
						  $ ssh {SUID}@cees-rcf.stanford.edu<b></li>
					  <li> <i>note: {SUID}@ is not requried if your SUID is the same as your workstation ID; .stanford.edu may not be necessary, since you're using the VPN</i>
						  </ul>
				  <h5 id=www_cees class='airy'>CEES website: <a href="https://cees.stanford.edu" target='_blank'> https://cees.stanford.edu</a> </h5>
				  <h5 id=mazama_pangea_docs class='airy'>CEES HPC general information: <a href="https://pangea.stanford.edu/research/groups/cees/hpc.php" target='_blank'> https://pangea.stanford.edu/research/groups/cees/hpc.php</a> </h5>
				  </p>
				  
			  </div>
			  </dif>
			  
		  </div>
		  </section>

  
  <!-- info Section -->
  <section id="info" class="bg">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading">In a nutshell</h2>
          <h3 class="section-subheading text-muted">All about Sherlock</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12">
          <h3 id="why" class="airy">Why should I use Sherlock?</h3>
          <!-- or, more precisely, "What is the Sherlock for, already?" -->
            <p class="text-muted">Using Sherlock for your work provides many
            advantages over individual solutions: hosted in an on-premises,
            state-of-the-art datacenter, the Sherlock cluster is powered and
            cooled by installations that are optimized for scientific
            computing.</p>
            <p class="text-muted">On Sherlock, simulations and workloads
            benefit from performance levels that only large scale HPC systems
            can offer: high-performance I/O infrastructure, petabytes of
            storage, large variety of hardware configurations, GPU
            accelerators, centralized system administration and management
            provided by the <a href="//srcc.stanford.edu">Stanford Research
            Computing Center</a> (SRCC).</p> 
            <p class="text-muted">Such features are not easily accessible at
            the departmental level, and often require both significant initial
            investments and recurring costs. Joining Sherlock allows
            researchers and faculty members to avoid those costs and benefit
            from economies of scale, as well as to access larger,
            professionally managed computing resources that what would not be 
            available on an individual or even departmental basis.</p>

            <p class="text-muted">Oh, and also, because even <a
            href="https://www.hbo.com/silicon-valley/cast-and-crew/richard">
            Richard Hendricks</a> wanted to use it! Yes, our very Sherlock was
            <a href="/img/richard.png">featured</a> in <a
            href="https://www.hbo.com/silicon-valley">HBO's Silicon Valley</a>
            <a href="https://www.hbo.com/silicon-valley/episodes/4/38-server-error">
            Season 4 finale</a>. So, if Richard needs Sherlock, it must be
            pretty darn good, right? ;)</p>

          <h3 id="cost" class="airy">How much does it cost?</h3>
            <p class="text-muted">Sherlock is free to use for anyone doing
            sponsored research at Stanford. Any faculty member can request
            access for research purposes, and get an account with a base
            storage allocation and unlimited compute time on the global, shared
            pool of resources.</p>
            <p class="text-muted">Stanford Research Computing provides faculty
            with the <a
            href="/docs/overview/concepts/#the-condominium-model">opportunity
            to purchase</a> from a <a
            href="https://srcc.stanford.edu/private/sherlock-qtr-order">catalog
            a recommended compute node configurations</a>, for the use of their
            research teams.  Using a traditional compute cluster condominium
            model, participating faculty and their teams get priority access to
            the resources they purchase. When those resources are idle, other
            "owners" can use them, until the purchasing owner wants to use
            them. When this happens, those other owners jobs are killed to free
            up resources. Participating owner PIs also have shared access to
            the original base Sherlock nodes, along with everyone else.</p>

          <h3 id="size" class="airy">How big is it?</h3>
            <p class="text-muted">Quite big! It's actually difficult to give a
            precise answer, as Sherlock is constantly evolving with new
            hardware additions.</p>
            <p class="text-muted">As of mid-2017, there were about 180 shared
            compute nodes available to all researchers, and more than 900
            additional nodes available to Sherlock <i>owners</i>, faculty who
            have augmented the cluster with their own purchases.</p>
            <p class="text-muted">For more details about Sherlock size and
            technical specifications, please refer to the <a
            href="/docs/overview/specs">tech specs</a> section of the <a
            href="/docs">documentation</a>. But with a computing power over 1
            Petaflops, Sherlock would have its place in the Top500 list of the
            500 most powerful computer systems in the world.</p>

          <h3 id="start" class="airy">Ok, how do I start?</h3>
            <p class="text-muted">You can <a id="account_request2"
            href="">request an account</a> right now, take a look at the <a
            href="docs/">documentation</a>, and drop us an <a
            href="mailto:srcc-support@stanford.edu">email</a> if
            you have any question.</p> 
            

          <h3 id="own" class="airy">I want my own nodes!</h3>
            <p class="text-muted">If you're interested in becoming an owner on
            Sherlock, and benefit from all the advantages associated, please
            take a look at the  <a
            href="https://srcc.stanford.edu/private/sherlock-qtr-order">catalog
            of configurations</a> and contact us at <a
            href="mailto:srcc-support@stanford.edu">srcc-support@stanford.edu
            </a> to let us know you're interested and we'll get back to
            you.</a>

            </div>

      </div>
    </div>
  </section>

  <!-- About Section -->
  <section id="about">
    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <h2 class="section-heading">Timeline:</h2>
          <h3 class="section-subheading text-muted">A tale of research computing at Stanford Earth</h3>
        </div>
      </div>
      <div class="row">
        <div class="col-lg-12">
          <ul class="timeline">
            <li>
              <div class="timeline-image">
                <img class="img-circle img-responsive" src="img/about/SRCF.jpg" alt="">
              </div>
              <div class="timeline-panel">
                  <div class="timeline-heading">
                      <h4>2010-2012</h4>
                      <h4 class="subheading">RCF: The original CEES cluster</h4>
                  </div>
                  <div class="timeline-body">
                      <p class="text-muted">Here, we tell our story of the history and motivation behind research computing at E3...</p> </div>
              </div>
              <div class="timeline-panel">
                <div class="timeline-heading">
                  <h4>2012-2019</h4>
                  <h4 class="subheading">Mazama: CEES Second Generation</h4>
                </div>
                <div class="timeline-body">
                  <p class="text-muted">As the role of HPC became more important in Earth Science research, the need for expanded, more advanced computing capabilities became apparent...</p> </div>
              </div>
            </li>
            <li class="timeline-inverted">
              <div class="timeline-image">
                <img class="img-circle img-responsive" src="img/about/sherlock.jpg" alt="">
              </div>
              <div class="timeline-panel">
                <div class="timeline-heading">
                  <h4>January 2014</h4>
                  <h4 class="subheading">Sherlock is born</h4>
                </div>
                <div class="timeline-body">
                  <p class="text-muted">With an initial seed of 120 nodes
                  funded by the University Provost, Sherlock opened for
                  production and started running its first jobs. More than 15
                  million jobs have been executed since then!</p> </div>
              </div>
            </li>
            <li>
              <div class="timeline-image">
                <img class="img-circle img-responsive" src="img/about/expansion.jpg" alt="">
              </div>
              <div class="timeline-panel">
                <div class="timeline-heading">
                  <h4>December 2014</h4>
                  <h4 class="subheading">First major expansion</h4>
                </div>
                <div class="timeline-body">
                  <p class="text-muted">During the first year, more than 200
                  nodes have been added to Sherlock, funded by several PIs from
                  many different Schools and Departments</p> </div>
              </div>
            </li>
            <li class="timeline-inverted">
              <div class="timeline-image">
                <img class="img-circle img-responsive" src="img/about/sh_full.jpg" alt="">
              </div>
              <div class="timeline-panel">
                <div class="timeline-heading">
                  <h4>December 2016</h4>
                  <h4 class="subheading">Sherlock reaches capacity</h4>
                </div>
                <div class="timeline-body">
                  <p class="text-muted">Sherlock reached 850 compute nodes,
                  which maxed out its initial Infiniband fabric capacity. As
                  demand for more compute power continued increasing, a new
                  fabric has been started to continue growing. A new Sherlock
                  was on its way!</p> </div>
              </div>
            </li>
            <li>
              <div class="timeline-image">
                <img class="img-circle img-responsive" src="img/about/sh2.jpg" alt="">
              </div>
              <div class="timeline-panel">
                <div class="timeline-heading">
                  <h4>July 2017</h4>
                  <h4 class="subheading">Sherlock 2.0</h4>
                </div>
                <div class="timeline-body">
                  <p class="text-muted">After a complete refresh of the
                  hardware, platform, software and services, Sherlock 2.0 opens
                  to all users</p> </div>
              </div>
            </li>
            <li class="timeline-inverted">
              <div class="timeline-image" style="background: white;">
                <img class="img-circle img-responsive" src="img/logo.png" alt=""
                     style="margin-top:5%; ">

              </div>
              <div class="timeline-panel">
                <div class="timeline-heading">
                  <h4>July 2018</h4>
                  <h4 class="subheading">Sherlock is whole again</h4>
                </div>
                <div class="timeline-body">
                  <p class="text-muted">The original Sherlock 1.0 nodes are
                  migrated to the new Sherlock 2.0 environment, and Sherlock
                  becomes a unique cluster again, featuring over 1,200 nodes,
                  22,000+ CPU cores, close to 700 GPUs, and providing over 1.5
                  PFlops of compute power to the Stanford research
                  community  
                  </p> </div>
              </div>
            </li>
            <li class="timeline-inverted">
              <div class="timeline-image" id="account_request3" style="cursor:pointer">
                <h4>Come
                  <br>join us
                  <br>today!
                </h4>
                
              </div>
            </li>
          </ul>
        </div>
      </div>
    </div>
  </section>


  <!-- jQuery -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" 
      integrity="sha256-ZosEbRLbNQzLpnKIkEdrPv7lOy9C27hHQ+Xp8a4MxAQ=" crossorigin="anonymous"></script>

  <!-- Bootstrap Core JavaScript -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" 
      integrity="sha256-U5ZEeKfGNOja007MMD3YBI0A3OSZOQbeG6z2f2Y0hu8=" crossorigin="anonymous"></script>

  <!-- Plugin JavaScript -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>

  <!-- Theme JavaScript -->
  <script src="js/shweb.min.js"></script>


  </div> <!-- #su-content end -->
 </div> <!-- #su-wrap end -->

 <!-- Global footer snippet start -->
 <div id="global-footer">
   <div class="container">
   <div class="row">
     <div id="bottom-logo" class="span2">
     <a href="//www.stanford.edu">
       <img src="//www.stanford.edu/su-identity/images/footer-stanford-logo@2x.png" alt="Stanford University" width="105" height="49"/>
     </a>
     </div>
     <!-- #bottom-logo end -->
     <div id="bottom-text" class="span10">
     <ul>
       <li class="home"><a href="//www.stanford.edu">SU Home</a></li>
       <li class="maps alt"><a href="//visit.stanford.edu/plan/maps.html">Maps &amp; Directions</a></li>
       <li class="search-stanford"><a href="//www.stanford.edu/search/">Search Stanford</a></li>
       <li class="terms alt"><a href="//www.stanford.edu/site/terms.html">Terms of Use</a></li>
       <li class="emergency-info"><a href="//emergency.stanford.edu">Emergency Info</a></li>
     </ul>
     </div> <!-- .bottom-text end -->
     <div class="clear"></div>
     <p class="copyright vcard">&copy; <span class="fn org">Stanford
     University</span>, <span class="adr"> <span
     class="locality">Stanford</span>, <span class="region">California</span>
     <span class="postal-code">94305</span></span>.&nbsp;&nbsp; <span
     id="copyright-complaint"><a
     href="https://uit.stanford.edu/security/copyright-infringement"
     class="copyright-complaint" >Copyright Complaints</a></span>
     </p>
   </div> <!-- .row end --> 
   </div> <!-- .container end --> 
 </div> <!-- global-footer end -->
 <!-- Global footer snippet end -->

<script src="//libraries.hund.io/status-js/status-3.7.1.js"></script>
<script>
  var statusWidget = new Status.Widget({
    hostname: "status.sherlock.stanford.edu",
    selector: "#status",
    display: {
        hideOnError: true,
        ledOnly: true,
        panePosition: "bottom-right"
    }
  });
</script>

</body>


</html>
